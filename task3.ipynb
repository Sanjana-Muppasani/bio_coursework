{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b741d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile \n",
    "import pandas as pd \n",
    "import os \n",
    "import numpy as np \n",
    "import lzma\n",
    "from sklearn import preprocessing, pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier \n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e1fc81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"../results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a4ce7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted and saved to: data/extracted_data/appointments\\description.txt\n",
      "File extracted and saved to: data/extracted_data/appointments\\participants.txt\n",
      "File extracted and saved to: data/extracted_data/appointments\\appointments.txt\n"
     ]
    }
   ],
   "source": [
    "filepath = \"data/appointments.tar.xz\"\n",
    "output_dir = \"data/extracted_data/appointments\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with lzma.open(filepath, \"rb\") as xz_file:\n",
    "    with tarfile.open(fileobj=xz_file, mode=\"r\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith(\".txt\"):\n",
    "                extracted_file = tar.extractfile(member)\n",
    "                if extracted_file is not None:\n",
    "                    output_path = os.path.join(output_dir, os.path.basename(member.name))\n",
    "                    with open(output_path, \"wb\") as output_file:\n",
    "                        output_file.write(extracted_file.read())\n",
    "                    print(f\"File extracted and saved to: {output_path}\")\n",
    "\n",
    "appointments_path = \"data/extracted_data/appointments/appointments.txt\"\n",
    "participants_path = \"data/extracted_data/appointments/participants.txt\"\n",
    "appointments_df = pd.read_csv(appointments_path, sep=r'\\s+')\n",
    "participants_df = pd.read_csv(participants_path, sep=r'\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1c8a769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>sms_received</th>\n",
       "      <th>advance</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987249982</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>Fri</td>\n",
       "      <td>fullfilled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5589977766</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>Fri</td>\n",
       "      <td>fullfilled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4262962299</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>Fri</td>\n",
       "      <td>fullfilled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8679512131</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>Fri</td>\n",
       "      <td>fullfilled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8841186448</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>Fri</td>\n",
       "      <td>fullfilled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant sms_received  advance  day  month weekday      status\n",
       "0   2987249982           NO        0   29      4     Fri  fullfilled\n",
       "1   5589977766           NO        0   29      4     Fri  fullfilled\n",
       "2   4262962299           NO        0   29      4     Fri  fullfilled\n",
       "3   8679512131           NO        0   29      4     Fri  fullfilled\n",
       "4   8841186448           NO        0   29      4     Fri  fullfilled"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appointments_df.head()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b51c526d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participant     0\n",
       "sms_received    0\n",
       "advance         0\n",
       "day             0\n",
       "month           0\n",
       "weekday         0\n",
       "status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appointments_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7e20b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge code\n",
    "combined_df = pd.merge(appointments_df, participants_df, on=\"participant\", how=\"inner\")\n",
    "combined_df = combined_df[combined_df[\"count\"] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ee283db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21           no-show\n",
       "27        fullfilled\n",
       "37        fullfilled\n",
       "47        fullfilled\n",
       "52           no-show\n",
       "             ...    \n",
       "110498    fullfilled\n",
       "110500    fullfilled\n",
       "110502    fullfilled\n",
       "110503    fullfilled\n",
       "110505    fullfilled\n",
       "Name: status, Length: 18838, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[\"status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca63540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df[\"sex\"] = combined_df[\"sex\"].replace({\"M\": 1, \"F\":0})\n",
    "# combined_df[\"sms_received\"] = combined_df[\"sms_received\"].replace({\"YES\":1, \"NO\":0})\n",
    "# combined_df[\"status\"] = combined_df[\"status\"].replace({\"fulfilled\":1, \"no-show\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c5d0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dynamically handlde categorical values and encoding them using sk-learn \n",
    "#nominal data scaled using standard scaler\n",
    "# categorical_columns = [\"sex\", \"sms_received\", \"status\",\"hipertension\",\"diabetes\",\"alcoholism\",\"weekday\"]\n",
    "# nominal_columns =  [\"age\", \"advance\", \"day\", \"month\", \"count\" ]\n",
    "# combined_df[categorical_columns] = combined_df[categorical_columns].apply(preprocessing.LabelEncoder().fit_transform)\n",
    "# for col in nominal_columns: \n",
    "#     combined_df[col] = preprocessing.StandardScaler().fit_transform(combined_df[[col]])\n",
    "# combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0b93eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_8636\\422018724.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  combined_df[\"status\"] = combined_df[\"status\"].replace({\"fullfilled\":0, \"no-show\":1})\n"
     ]
    }
   ],
   "source": [
    "combined_df[\"status\"] = combined_df[\"status\"].replace({\"fullfilled\":0, \"no-show\":1})\n",
    "categorical_features = ['sms_received', 'weekday', 'sex', 'hipertension', 'diabetes', 'alcoholism']\n",
    "numerical_features = ['advance', 'day', 'month', 'age', 'count']\n",
    "\n",
    "categorical_transformer = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "numerical_transformer = preprocessing.StandardScaler() \n",
    "\n",
    "# 4. Create the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ])\n",
    "\n",
    "preprocessing_pipeline = pipeline.Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "df_transformed_array = preprocessing_pipeline.fit_transform(combined_df)\n",
    "feature_names = (\n",
    "    preprocessing_pipeline.named_steps['preprocessor']\n",
    "    .named_transformers_['cat']\n",
    "    .get_feature_names_out(categorical_features)\n",
    ")\n",
    "all_feature_names = list(feature_names) + numerical_features \n",
    "df_transformed_scaled = pd.DataFrame(df_transformed_array, columns=all_feature_names)\n",
    "df_transformed_scaled[\"status\"] = combined_df[\"status\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2033121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(31)\n",
    "cv = model_selection.StratifiedKFold(n_splits=10, shuffle=True, random_state=rng)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a57c1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_transformed_scaled[\"status\"]\n",
    "x = df_transformed_scaled.drop(columns=[\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "664dc935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (5-fold CV): 0.7932\n",
      "Mean F1 Score (5-fold CV): 0.0000\n"
     ]
    }
   ],
   "source": [
    "#iniitalizing cv and rng \n",
    "#for an 80-20 distribution \n",
    "rf = RandomForestClassifier(1000, max_depth=4, random_state=rng, criterion=\"gini\", max_features=4)\n",
    "\n",
    "#fitting the feeatures and target variable to the model, selected scoring criteria and implemeneting CV, this automatically does the test trian split \n",
    "scores_rf = model_selection.cross_validate(rf, x, y, scoring = [\"f1\", \"accuracy\"], cv=cv)\n",
    "\n",
    "mean_accuracy = scores_rf[\"test_accuracy\"].mean()\n",
    "mean_f1_macro = scores_rf[\"test_f1\"].mean()\n",
    "\n",
    "print(f\"Mean Accuracy (5-fold CV): {mean_accuracy:.4f}\")\n",
    "print(f\"Mean F1 Score (5-fold CV): {mean_f1_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dbfb0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier(random_state=rng) \n",
    "# param_grid_rf = {\n",
    "#     'n_estimators': [100, 200],        \n",
    "#     'max_depth': [3, 4, 5],              \n",
    "#     'criterion': [\"gini\", \"entropy\"],      \n",
    "#     'max_features': [4, 6]       \n",
    "# }\n",
    "\n",
    "# scoring_metrics = {\n",
    "#     'F1_Score': 'f1',\n",
    "#     'Accuracy': 'accuracy'\n",
    "# }\n",
    "# refit_metric = \"F1_Score\"\n",
    "\n",
    "# grid_search_rf = model_selection.GridSearchCV(\n",
    "#     estimator=rf,\n",
    "#     param_grid=param_grid_rf,\n",
    "#     scoring=scoring_metrics,\n",
    "#     cv=cv,\n",
    "#     refit=refit_metric, \n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# print(f\"Starting Grid Search for Random Forest. Testing {len(param_grid_rf['n_estimators']) * len(param_grid_rf['max_depth']) * len(param_grid_rf['criterion']) * len(param_grid_rf['max_features'])} combinations...\")\n",
    "\n",
    "\n",
    "# grid_search_rf.fit(x, y) \n",
    "\n",
    "# print(f\"\\n--- Random Forest Grid Search Results ---\")\n",
    "\n",
    "# best_f1_score_rf = grid_search_rf.best_score_\n",
    "# print(f\"Best Model Selected using {refit_metric}: {grid_search_rf.best_params_}\")\n",
    "# print(f\"Best {refit_metric} achieved (5-fold CV mean): {best_f1_score_rf:.4f}\")\n",
    "\n",
    "\n",
    "# results_df = pd.DataFrame(grid_search_rf.cv_results_)\n",
    "# best_index = grid_search_rf.best_index_\n",
    "\n",
    "# mean_accuracy_best = results_df.loc[best_index, 'mean_test_Accuracy']\n",
    "# mean_f1_best = results_df.loc[best_index, 'mean_test_F1_Score']\n",
    "\n",
    "# print(f\"Mean Accuracy of the Best RF Model (5-fold CV mean): {mean_accuracy_best:.4f}\")\n",
    "# print(f\"Mean F1 Score of the Best RF Model (5-fold CV mean): {mean_f1_best:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7236c979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (10-fold CV) - GB: 0.7876\n",
      "Mean F1 Score (10-fold CV) - GB: 0.3738\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=4, random_state=rng)\n",
    "scores_gb = model_selection.cross_validate(gb, x, y, scoring = [\"f1\", \"accuracy\"], cv=cv)\n",
    "\n",
    "mean_accuracy_gb = scores_gb[\"test_accuracy\"].mean()\n",
    "mean_f1_macro_gb = scores_gb[\"test_f1\"].mean()\n",
    "print(f\"Mean Accuracy (10-fold CV) - GB: {mean_accuracy_gb:.4f}\")\n",
    "print(f\"Mean F1 Score (10-fold CV) - GB: {mean_f1_macro_gb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "420489a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid_gb = {\n",
    "#     'n_estimators': [100, 200],         \n",
    "#     'learning_rate': [0.1, 0.5, 1.0],      \n",
    "#     'max_depth': [4],                 \n",
    "# }\n",
    "\n",
    "\n",
    "# gb = GradientBoostingClassifier(random_state=rng)\n",
    "\n",
    "# grid_search_gb = model_selection.GridSearchCV(\n",
    "#     estimator=gb,\n",
    "#     param_grid=param_grid_gb,\n",
    "#     scoring=['f1',\"accuracy\"], \n",
    "#     cv=cv,\n",
    "#     n_jobs=-1 \n",
    "# )\n",
    "\n",
    "\n",
    "# grid_search_gb.fit(x, y)\n",
    "\n",
    "\n",
    "# best_f1_score_gb = grid_search_gb.best_score_\n",
    "# print(f\"Best F1 Score found by Grid Search - GB: {best_f1_score_gb:.4f}\")\n",
    "# best_params_gb = grid_search_gb.best_params_\n",
    "# print(f\"Best parameters - GB: {best_params_gb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f303a7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (10-fold CV) - KNN: 0.7734\n",
      "Mean F1 Score (10-fold CV) - KNN: 0.2782\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5) \n",
    "\n",
    "# Perform cross-validation\n",
    "scores_knn = model_selection.cross_validate(knn, x, y, scoring = [\"f1\", \"accuracy\"], cv=cv)\n",
    "\n",
    "# Calculate and print the mean scores\n",
    "mean_accuracy_knn = scores_knn[\"test_accuracy\"].mean()\n",
    "mean_f1_macro_knn = scores_knn[\"test_f1\"].mean()\n",
    "\n",
    "print(f\"Mean Accuracy (10-fold CV) - KNN: {mean_accuracy_knn:.4f}\")\n",
    "print(f\"Mean F1 Score (10-fold CV) - KNN: {mean_f1_macro_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c442e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (10-fold CV) - LR: 0.7891\n",
      "Mean F1 Score (10-fold CV) - LR: 0.0385\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear', random_state=rng, max_iter=1000, C=1.0) \n",
    "\n",
    "# Perform cross-validation\n",
    "scores_lr = model_selection.cross_validate(lr, x, y, scoring = [\"f1\", \"accuracy\"], cv=cv)\n",
    "\n",
    "# Calculate and print the mean scores\n",
    "mean_accuracy_lr = scores_lr[\"test_accuracy\"].mean()\n",
    "mean_f1_macro_lr = scores_lr[\"test_f1\"].mean()\n",
    "\n",
    "print(f\"Mean Accuracy (10-fold CV) - LR: {mean_accuracy_lr:.4f}\")\n",
    "print(f\"Mean F1 Score (10-fold CV) - LR: {mean_f1_macro_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = list(zip(\"rf_gb_lr\", [rf, gb, lr]))\n",
    "s = StackingClassifier(estimators, final_estimator=GradientBoostingClassifier(random_state=rng, n_estimators=100, learning_rate=0.5, max_depth=4))\n",
    "scores = model_selection.cross_val_score(s, x, y, scoring=\"f1\", cv=cv).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5532761b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.14654588616542488)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059937fe",
   "metadata": {},
   "source": [
    "Tried using hard voting, results were lower compared to soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "266f3b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.08881125210832329)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "v = VotingClassifier(estimators, voting=\"soft\")\n",
    "v_scores = model_selection.cross_val_score(v, x, y, scoring=\"f1\", cv = cv).mean()\n",
    "v_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b9a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21        False\n",
       "27        False\n",
       "37         True\n",
       "47        False\n",
       "52        False\n",
       "          ...  \n",
       "110498     True\n",
       "110500    False\n",
       "110502    False\n",
       "110503    False\n",
       "110505     True\n",
       "Name: count, Length: 18838, dtype: bool"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "73a4d604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Checking Model Correlation ---\n",
      "Generating predictions to check correlation (this takes a moment)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'sms_received'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:443\u001b[39m, in \u001b[36m_get_column_indices\u001b[39m\u001b[34m(X, key)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     col_idx = \u001b[43mall_columns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers.Integral):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'sms_received'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Get out-of-fold probability predictions\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating predictions to check correlation (this takes a moment)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m pred_rf = \u001b[43mmodel_selection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_val_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpredict_proba\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m[:, \u001b[32m1\u001b[39m]\n\u001b[32m     33\u001b[39m pred_gb = model_selection.cross_val_predict(pipe_gb, x, y, cv=\u001b[32m5\u001b[39m, method=\u001b[33m'\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m'\u001b[39m)[:, \u001b[32m1\u001b[39m]\n\u001b[32m     35\u001b[39m correlation = np.corrcoef(pred_rf, pred_gb)[\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1234\u001b[39m, in \u001b[36mcross_val_predict\u001b[39m\u001b[34m(estimator, X, y, groups, cv, n_jobs, verbose, params, pre_dispatch, method)\u001b[39m\n\u001b[32m   1231\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m   1232\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m   1233\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m-> \u001b[39m\u001b[32m1234\u001b[39m predictions = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1247\u001b[39m inv_test_indices = np.empty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m   1248\u001b[39m inv_test_indices[test_indices] = np.arange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1319\u001b[39m, in \u001b[36m_fit_and_predict\u001b[39m\u001b[34m(estimator, X, y, train, test, fit_params, method)\u001b[39m\n\u001b[32m   1317\u001b[39m     estimator.fit(X_train, **fit_params)\n\u001b[32m   1318\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1320\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[32m   1321\u001b[39m predictions = func(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:655\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    651\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    652\u001b[39m     )\n\u001b[32m    654\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:589\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    583\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    584\u001b[39m     step_idx=step_idx,\n\u001b[32m    585\u001b[39m     step_params=routed_params[name],\n\u001b[32m    586\u001b[39m     all_params=raw_params,\n\u001b[32m    587\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\joblib\\memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:988\u001b[39m, in \u001b[36mColumnTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    985\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_transformers()\n\u001b[32m    986\u001b[39m n_samples = _num_samples(X)\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_remainder(X)\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:541\u001b[39m, in \u001b[36mColumnTransformer._validate_column_callables\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    539\u001b[39m         columns = columns(X)\n\u001b[32m    540\u001b[39m     all_columns.append(columns)\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     transformer_to_input_indices[name] = \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[38;5;28mself\u001b[39m._columns = all_columns\n\u001b[32m    544\u001b[39m \u001b[38;5;28mself\u001b[39m._transformer_to_input_indices = transformer_to_input_indices\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanja\\bio_coursework\\.venv\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:451\u001b[39m, in \u001b[36m_get_column_indices\u001b[39m\u001b[34m(X, key)\u001b[39m\n\u001b[32m    448\u001b[39m         column_indices.append(col_idx)\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mA given column is not a column of the dataframe\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n",
      "\u001b[31mValueError\u001b[39m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "categorical_features = ['sms_received', 'weekday', 'sex', 'hipertension', 'diabetes', 'alcoholism']\n",
    "numerical_features = ['advance', 'day', 'month', 'age', 'count']\n",
    "\n",
    "categorical_transformer = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "numerical_transformer = preprocessing.StandardScaler() \n",
    "\n",
    "# 4. Create the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numerical_transformer, numerical_features)\n",
    "    ])\n",
    "\n",
    "preprocessing_pipeline = pipeline.Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "    ])\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=rng, criterion=\"gini\")\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.5, max_depth=4, random_state=rng)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STRATEGY 1: Check Correlation first\n",
    "# ---------------------------------------------------------\n",
    "print(\"--- Step 1: Checking Model Correlation ---\")\n",
    "\n",
    "# We need pipelines to run cross_val_predict on raw X\n",
    "pipe_rf = pipeline.Pipeline([('prep', preprocessor), ('clf', rf)])\n",
    "pipe_gb = pipeline.Pipeline([('prep', preprocessor), ('clf', gb)])\n",
    "\n",
    "# Get out-of-fold probability predictions\n",
    "print(\"Generating predictions to check correlation (this takes a moment)...\")\n",
    "pred_rf = model_selection.cross_val_predict(pipe_rf, x, y, cv=5, method='predict_proba')[:, 1]\n",
    "pred_gb = model_selection.cross_val_predict(pipe_gb, x, y, cv=5, method='predict_proba')[:, 1]\n",
    "\n",
    "correlation = np.corrcoef(pred_rf, pred_gb)[0, 1]\n",
    "print(f\"Correlation between RF and GB predictions: {correlation:.4f}\")\n",
    "if correlation > 0.90:\n",
    "        print(\">> WARNING: High correlation. Ensembling might have diminishing returns.\")\n",
    "else:\n",
    "    print(\">> Good diversity. Ensembling should help.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_coursework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
